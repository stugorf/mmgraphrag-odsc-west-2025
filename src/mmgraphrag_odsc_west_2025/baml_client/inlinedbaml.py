###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml-py
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "captions.baml": "// Define Image model for the results of a LLaVA analysis\nclass ImageCaption {\n  caption string @description(#\"A concise description of the image.\"#)\n}\n\n\n// Create a function to extract the image from a base64 encoding of the image.\nfunction ExtractImageCaption(img: image) -> ImageCaption {\n  client OllamaGemma3_12b // OllamaLLaVA // OllamaPhi4\n  prompt #\"\n    {{_.role(\"user\")}}\n    Write a caption for this image: {{img}}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n\ntest test_image_caption {\n  functions [ExtractImageCaption]\n  args {\n    img {\n      file \"../images/e_COCO_val2014_000000000757.jpg\"\n    }\n  }\n}\n",
    "clients.baml": "client<llm> OllamaGemma3_12b {\n  provider \"openai-generic\"\n  options {\n    base_url \"http://localhost:11434/v1\"\n    model gemma3:12b\n    temperature 0.1\n    top_k 64\n    top_p 0.95\n    min_p 0.0\n  }\n}\n\nclient<llm> OllamaPhi4 {\n  provider \"openai-generic\"\n  options {\n    base_url \"http://localhost:11434/v1\"\n    model phi4\n    temperature 0.0\n  }\n}\n\nclient<llm> OllamaLlama3Vision {\n  provider \"openai-generic\"\n  options {\n    base_url \"http://localhost:11434/v1\"\n    model llama3.2-vision:11b\n    temperature 0.0\n  }\n}\n\nclient<llm> OllamaLLaVA {\n  provider \"openai-generic\"\n  options {\n    base_url \"http://localhost:11434/v1\"\n    model llava\n    temperature 0.0\n  }\n}\n\nclient<llm> OllamaLlama3 {\n  provider \"openai-generic\"\n  options {\n    base_url \"http://localhost:11434/v1\"\n    model llama3.2:3b\n    temperature 0.0\n  }\n}\n\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    mutliplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "features.baml": "// Define Image model for the results of a LLaVA analysis\n\nclass ImageObject {\n  name string @description(#\"A single word name for the object.\"#)\n  colors string[] @description(#\"A list of the top three predominant colors found in just the object.\"#)\n  bounding_box float[] @description(#\"The bounding box for the object. For example [194.26, 236.69, 21.22, 14.05]\"#)\n\n}\n\nclass ImageFeatures {\n  colors string[] @description(#\"A list of the top three predominant colors found in the entire image.\"#)\n  sharpness string @description(#\"A single word description of the image's sharpness\"#)\n  complexity string @description(#\"A single word description of the image's complexity\"#)\n  textures string[] @description(#\"A list of single words describing the textures in the image\"#)\n}\n\nclass ImageAnalysis {\n  description ImageCaption\n  features ImageFeatures\n  objects ImageObject[]?\n}\n\nfunction ExtractImageFeatures(img: image) -> ImageFeatures {\n    client OllamaPhi4\n    prompt #\"\n      {{_.role(\"user\")}}\n      Extract features in this image: {{img}}\n\n      {{ ctx.output_format }}\n    \"#\n}\n\nfunction ExtractImageObjects(img: image) -> ImageObject[] {\n    client OllamaPhi4\n    prompt #\"\n      {{_.role(\"user\")}}\n      Extract objects in this image: {{img}}\n\n      {{ ctx.output_format }}\n    \"#\n}\n\nfunction AnalyzeImage(img: image) -> ImageAnalysis {\n  client OllamaPhi4\n    prompt #\"\n      {{_.role(\"user\")}}\n      Extract the caption and features in this image: {{img}}\n\n      {{ ctx.output_format }}\n    \"#\n}\n\n\ntest test_image_features {\n  functions [ExtractImageFeatures]\n  args {\n    img {\n      file \"../images/e_COCO_val2014_000000000757.jpg\"\n   }\n  }\n}\n\ntest test_image_objects {\n  functions [ExtractImageObjects]\n  args {\n    img {\n      file \"../images/e_COCO_val2014_000000000757.jpg\"\n   }\n  }\n}\n\ntest test_image_analysis {\n  functions [AnalyzeImage]\n  args {\n    img {\n      file \"../images/e_COCO_val2014_000000000757.jpg\"\n   }\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.84.4\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "hardware.baml": "",
}

def get_baml_files():
    return file_map